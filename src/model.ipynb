{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all data into single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " FutureWarning:/Users/adorman/Documents/master-thesis/src/data_preprocessing.py:43: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      " ImplicitModificationWarning:/Users/adorman/Documents/master-thesis/src/data_preprocessing.py:55: Trying to modify attribute `.obs` of view, initializing view as actual.\n"
     ]
    }
   ],
   "source": [
    "adata = preprocess_data('../data/initial_10x_outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_bulk = pseudo_bulk(adata=adata,col='cell_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 9 × 1742749"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pseudo-bulk bigwig file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create file with cell barcodes and group \n",
    "D8_1 =  adata[adata.obs.batch == '0']\n",
    "\n",
    "barcodes = D8_1.obs.cell_type\n",
    "barcodes.index = [b[:-2] for b in barcodes.index.values]\n",
    "barcodes.to_csv('../results/cell_types.tsv', header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sinto filterbarcodes [-h] -b BAM -c CELLS [-t] [-p NPROC]\n",
      "                            [--barcode_regex BARCODE_REGEX]\n",
      "                            [--barcodetag BARCODETAG] [--outdir OUTDIR] [-s]\n",
      "\n",
      "Filter reads based on input list of cell barcodes\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -b BAM, --bam BAM     Input bam file (must be indexed)\n",
      "  -c CELLS, --cells CELLS\n",
      "                        File or comma-separated list of cell barcodes. Can be\n",
      "                        gzip compressed\n",
      "  -t, --trim_suffix     Remove trail 2 characters from cell barcode in BAM\n",
      "                        file\n",
      "  -p NPROC, --nproc NPROC\n",
      "                        Number of processors (default = 1)\n",
      "  --barcode_regex BARCODE_REGEX\n",
      "                        Regular expression used to extract cell barcode from\n",
      "                        read name. If None (default), extract cell barcode\n",
      "                        from read tag. Use \"[^:]*\" to match all characters up\n",
      "                        to the first colon.\n",
      "  --barcodetag BARCODETAG\n",
      "                        Read tag storing cell barcode information (default =\n",
      "                        \"CB\")\n",
      "  --outdir OUTDIR       Output file directory\n",
      "  -s, --sam             Output sam format (default bam output)\n"
     ]
    }
   ],
   "source": [
    "!sinto filterbarcodes -b ../data/initial_10x_outputs/D8_1_ATAC.bam -c ../results/cell_types.tsv --outdir ../results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bam bamCoverage --b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model class + functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNet(nn.Module):\n",
    "    def __init__(self, seq_len=1000, nb_conv=10, nb_filters=64, first_kernel=25, rest_kernel=3):\n",
    "        super().__init__()\n",
    "        \"\"\" BPNet architechture as in paper \n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        seq_len: int (default 1000)\n",
    "            length of the input DNA sequence\n",
    "\n",
    "        nb_conv: int (default 10)\n",
    "            number of convolutional layers\n",
    "\n",
    "        nb_filters: int (default 64)\n",
    "            number of filters in the convolutional layers\n",
    "\n",
    "        first_kernel: int (default 25)\n",
    "            size of the kernel in the first convolutional layer\n",
    "\n",
    "        rest_kernel: int (default 3)\n",
    "            size of the kernel in all convolutional layers except the first one\n",
    "\n",
    "        Model Architecture \n",
    "        ------------------------\n",
    "\n",
    "        - Body: sequence of convolutional layers with residual skip connections, dilated convolutions, \n",
    "        and  ReLU activation functions\n",
    "\n",
    "        - Head: \n",
    "            > Profile prediction head: a multinomial probability of Tn5 insertion counts at each position \n",
    "            in the input sequence, deconvolution layer\n",
    "            > Total count prediction: the total Tn5 insertion counts over the input region, global average\n",
    "            poooling and linear layer predicting the total count per strand\n",
    "        \n",
    "        The predicted (expected) count at a specific position is a multiplication of the predicted total \n",
    "        counts and the multinomial probability at that position.\n",
    "\n",
    "        -------------------------\n",
    "        \n",
    "        Reference: Avsec, Ž., Weilert, M., Shrikumar, A. et al. Base-resolution models of transcription-factor binding \n",
    "        reveal soft motif syntax. Nat Genet 53, 354–366 (2021). https://doi.org/10.1038/s41588-021-00782-6\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        #Define parameters\n",
    "        self.seq_len = seq_len\n",
    "        self.nb_conv = nb_conv\n",
    "        self.nb_filters = nb_filters\n",
    "        self.first_kernel = first_kernel\n",
    "        self.rest_kernel = rest_kernel\n",
    "\n",
    "        #Convolutional layers\n",
    "        self.convlayers = nn.ModuleList()\n",
    "\n",
    "        self.convlayers.append(nn.Conv1d(in_channels=4, \n",
    "                                         out_channels=self.nb_filters,\n",
    "                                         kernel_size=self.first_kernel,\n",
    "                                         dilation=1, padding='same'))\n",
    "        for i in range (1,self.nb_conv):\n",
    "            self.convlayers.append(nn.Conv1d(in_channels=self.nb_filters, \n",
    "                                         out_channels=self.nb_filters,\n",
    "                                         kernel_size=self.rest_kernel,\n",
    "                                         dilation=2**i, padding='same'))\n",
    "        #Profile prediction head   \n",
    "        self.deconv = nn.ConvTranspose1d(self.nb_filters, 2, kernel_size=25, padding=12)\n",
    "        \n",
    "        #Total count prediction head\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.linear = nn.Linear(self.nb_filters,2)\n",
    "\n",
    "            \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = F.relu(self.convlayers[0](x))\n",
    "        for layer in self.convlayers[1:]:\n",
    "            x = F.relu(layer(x)) + x\n",
    "\n",
    "        #Profile shape\n",
    "        px = self.deconv(x)\n",
    "        px = px.reshape((-1,2))\n",
    "\n",
    "        #Total count head\n",
    "        cx = self.global_pool(x)  \n",
    "        cx = cx.squeeze(-1)\n",
    "        cx = self.linear(cx)\n",
    "\n",
    "        return x, px, cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts the base-resolution 1,000 bp length Tn5 insertion count profile using two complementary outputs: (1) the total Tn5 insertion counts over the 1,000 bp region, and (2) a multinomial probability of Tn5 insertion counts at each position in the 1,000 bp sequence. The predicted (expected) count at a specific position is a multiplication of the predicted total counts and the multinomial probability at that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = BPNet()\n",
    "input = torch.randn(4, 1000)\n",
    "output = m(input)\n",
    "\n",
    "output[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeKIra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
